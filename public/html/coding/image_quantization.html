<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Python Image Quantizer - Jacob Brook</title>
    <link rel="stylesheet" href="../../css/style.css">
    <style>
        /* Article-specific styles */
        body {
            font-family: sans-serif;
            padding: 20px;
        }

        .interactive-area {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ccc;
        }

        #status {
            margin-top: 10px;
            font-style: italic;
            color: #555;
        }

        #outputImageContainer {
            margin-top: 20px;
            border: 1px dashed #aaa;
            min-height: 200px;
        }

        img {
            max-width: 100%;
            display: block;
        }

        textarea {
            width: 100%;
            min-height: 150px;
            margin-bottom: 10px;
        }

        button {
            padding: 8px 15px;
            margin-top: 10px;
        }

        .controls label {
            display: block;
            margin-top: 10px;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.25.1/full/pyodide.js"></script>
</head>

<body>
    <header>
        <div class="header-container">
            <div class="site-title">
                <h1><a href="/coding">Jacob Brook - Coding Articles</a></h1>
            </div>
            <nav class="main-navigation">
                <ul class="site-menu">
                    <li><a href="/prints">Prints</a></li>
                    <li><a href="/coding">Back to Coding Hub</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section class="article-content">
            <h2>Interactive Image Quantizer Demo (Python in Browser)</h2>
            <p>The core functionality of the image quantizer is able to be run in the browser thanks to <a
                    href="https://pyodide.org/">Pyodide</a>.</p>

            <div class="interactive-area">
                <h3>Try it Out!</h3>

                <div class="controls">
                    <label for="imageUpload">1. Upload an image:</label>
                    <input type="file" id="imageUpload" accept="image/*">

                    <label for="numColors">2. Number of Colors (K-Means):</label>
                    <input type="number" id="numColors" value="8" min="2" max="50">

                    <label for="windowSize">3. Window Size:</label>
                    <input type="number" id="windowSize" value="12" min="2" max="50">

                    <button id="quantizeButton">4. Quantize Image</button>
                </div>

                <div id="status">Pyodide Status: Not loaded yet.</div>

                <h4>Original Image:</h4>
                <div id="originalImageContainer">
                    <img id="originalImage" src="#" alt="Original will appear here" style="display:none;" />
                </div>

                <h4>Quantized Image:</h4>
                <div id="outputImageContainer">
                    <img id="outputImage" src="#" alt="Quantized image will appear here" style="display:none;" />
                </div>

                <h4>Python Code to Run:</h4>
                <p>For this demo, we'll adapt parts of your Python script. The full Tkinter GUI is replaced by this web
                    page.</p>
                <textarea id="pythonCode" spellcheck="false">
from PIL import Image
import io
import numpy as np
import pyodide
from sklearn.cluster import KMeans
from sklearn.utils import shuffle

# --- Helper Function for NumPy Mode ---
def numpy_mode(arr):
    """
    Calculates the mode (most frequent value) of a 1D array using NumPy.
    Assumes non-negative integer inputs suitable for bincount.
    """
    if arr.size == 0:
        return 0
    arr_int = arr.astype(np.intp)
    if np.any(arr_int < 0):
        arr_int = arr_int[arr_int >= 0]
        if arr_int.size == 0:
            return 0
    # Handle case where max index in arr_int might be large but counts are sparse
    # bincount size is max(arr_int) + 1. Ensure it's not excessively large.
    # Add a check or handle potential MemoryError if max(arr_int) is huge.
    # For typical label indices (0 to num_colors-1), this should be fine.
    try:
        counts = np.bincount(arr_int)
    except MemoryError:
        print(
            f"MemoryError in bincount. Max index: {np.max(arr_int)}. Array size: {arr_int.size}"
        )
        # Fallback or raise error - returning 0 might hide issues
        # Find unique values and their counts as an alternative if bincount fails
        unique_vals, counts = np.unique(arr_int, return_counts=True)
        if unique_vals.size == 0:
            return 0
        return unique_vals[np.argmax(counts)]  # Return the value with max count

    if counts.size == 0:
        return 0
    return np.argmax(counts)

def quantizer_sklearn_py(image_bytes_proxy, num_colors_py, window_size_py):
    import js # For logging
    js.console.log(f"Python: Quantizing with K-Means: {num_colors_py} colors, Window: {window_size_py}")

    try:
        python_image_bytes = image_bytes_proxy.to_py()
        image_pil = Image.open(io.BytesIO(python_image_bytes)).convert("RGB")
    except Exception as e:
        js.console.error(f"Python: Error opening image: {str(e)}")
        return None
    
    img = np.array(image_pil) # Renamed from img_np for consistency with your original code
    h_orig, w_orig, c = img.shape

    # --- Padding --- (Your existing logic)
    pad_size = window_size_py // 2 # Use window_size_py
    padded_img = np.pad(
        img,
        ((pad_size, pad_size), (pad_size, pad_size), (0, 0)),
        mode="edge",
    )
    h_padded, w_padded, _ = padded_img.shape
    # js.updateProgress(10) # If using progress callback

    # --- K-Means Clustering ---
    img_array_padded = padded_img.reshape(h_padded * w_padded, c)
    img_array_orig = img.reshape(h_orig * w_orig, c)
    n_pixels = img_array_orig.shape[0]
    n_samples = min(1000, n_pixels) # Or adjust sample size for browser performance

    if n_samples <= 0:
        js.console.warn("Python: Not enough pixels to sample for KMeans. Returning original.")
        # Fallback: return original image bytes
        output_buffer = io.BytesIO()
        image_pil.save(output_buffer, format="PNG")
        return output_buffer.getvalue()

    # Consider fewer n_init/max_iter for browser speed
    kmeans = KMeans(n_clusters=num_colors_py, init="k-means++", n_init=3, random_state=0, max_iter=50) 
    
    # Sample pixels for fitting KMeans
    img_array_sample = shuffle(img_array_orig, random_state=0, n_samples=n_samples)
    try:
        kmeans.fit(img_array_sample)
    except Exception as e:
        js.console.error(f"Python: KMeans fit error: {str(e)}")
        return None

    labels = kmeans.predict(img_array_padded) # Predict on the full PADDED array
    dominant_colors = np.clip(kmeans.cluster_centers_, 0, 255).astype(np.uint8)
    # js.updateProgress(40)

    labels_reshaped = labels.reshape(h_padded, w_padded) # Use h_padded, w_padded

    # --- Window Mode Calculation (SERIAL) ---
    # Construct windows_for_mode (Your existing logic - ensure bounds are correct with h_orig, w_orig)
    windows_for_mode = np.zeros((h_orig, w_orig, window_size_py * window_size_py), dtype=labels.dtype)
    for i in range(h_orig):
        for j in range(w_orig):
            # Extract window from labels_reshaped (which is based on padded image)
            # The indices i, j here are for the *original* image dimensions
            # So we need to map them to the padded labels_reshaped
            window = labels_reshaped[i : i + window_size_py, j : j + window_size_py]
            windows_for_mode[i, j, :] = window.flatten()
    
    js.console.log("Python: Starting serial mode calculation...")
    try:
        # This uses your numpy_mode function
        most_common_labels = np.apply_along_axis(numpy_mode, axis=2, arr=windows_for_mode)
    except Exception as e:
        js.console.error(f"Python: Error during mode calculation: {str(e)}")
        return None
    js.console.log("Python: Mode calculation complete.")
    # js.updateProgress(90)

    # --- Create Quantized Image --- (Your existing logic for indexing with dominant_colors)
    index_labels = most_common_labels.astype(np.intp) 
    # Ensure index_labels is 2D matching original image dimensions if necessary, though apply_along_axis should preserve first N-1 dims.
    # apply_along_axis on (h_orig, w_orig, N*N) with axis=2 will result in (h_orig, w_orig)
    # So, index_labels.reshape(h_orig, w_orig) might not be needed if already 2D.
    # Check shape: js.console.log(f"Python: index_labels shape: {index_labels.shape}")
    
    quantized_img = np.zeros_like(img) # Using the shape of the original unpadded 'img'

    num_dominant_colors = dominant_colors.shape[0]
    if num_dominant_colors > 0:
        # Your separate channel indexing logic here...
        # Make sure index_labels values are < num_dominant_colors
        if np.any(index_labels >= num_dominant_colors):
            js.console.error(f"Python: Error - label index out of bounds. Max label: {np.max(index_labels)}, Num colors: {num_dominant_colors}")
            # Clip labels or handle error
            index_labels = np.clip(index_labels, 0, num_dominant_colors - 1)

        red_channel = dominant_colors[:, 0]
        green_channel = dominant_colors[:, 1]
        blue_channel = dominant_colors[:, 2]

        quantized_img[:,:,0] = red_channel[index_labels]
        quantized_img[:,:,1] = green_channel[index_labels]
        quantized_img[:,:,2] = blue_channel[index_labels]
    else:
        js.console.warn("Python: No dominant colors found, result will be black or original.")
        # Optionally return the original image or a black image if no colors
        # For now, it will return the zeros_like(img) if num_dominant_colors is 0

    # --- Output ---
    quantized_img_pil = Image.fromarray(quantized_img.astype(np.uint8))
    output_buffer = io.BytesIO()
    quantized_img_pil.save(output_buffer, format="PNG")
    # js.updateProgress(100)
    js.console.log("Python: Quantization function finished.")
    return output_buffer.getvalue()

# Make sure this main function is available to JavaScript
print("Python setup complete. 'your_quantizer_sklearn_py' is defined.")
# No explicit 'set' to js.pyodide.globals needed here if JS calls it via runPythonAsync correctly.
                    

# This is the Python function that JavaScript will call.
# It expects a PyProxy to the JS Uint8Array for image_bytes_proxy,
# and standard Python numbers for num_colors_py and window_size_py.
def quantize_image_placeholder_py(image_bytes_proxy, num_colors_py, window_size_py):
    # Convert the PyProxy of JavaScript's Uint8Array to Python bytes
    # This is crucial for PIL to read the image data.
    try:
        python_image_bytes = image_bytes_proxy.to_py()
    except Exception as e:
        import js
        js.console.error(f"Python Error: Failed to convert image_bytes_proxy to Python bytes: {str(e)}")
        return None

    try:
        img = Image.open(io.BytesIO(python_image_bytes))
        img = img.convert("RGB") # Ensure RGB for consistent processing

        # Simulate some processing (e.g., your quantization logic would go here)
        output_img_array = np.array(img)
        # Example: Invert colors as a placeholder for quantization
        output_img_array = 255 - output_img_array
        processed_img = Image.fromarray(output_img_array.astype(np.uint8))

        # Convert processed PIL Image object back to bytes to return to JavaScript
        output_buffer = io.BytesIO()
        processed_img.save(output_buffer, format="PNG") # Save as PNG bytes
        return output_buffer.getvalue() # Returns Python bytes object
    except Exception as e:
        # If an error occurs, print it to the JS console for debugging
        import js
        js.console.error(f"Python Error in quantize_image_placeholder_py: {str(e)}")
        return None # Indicate failure

# This print confirms the Python script in the textarea has run and defined the function.
print("Python setup complete. 'quantize_image_placeholder_py' is defined and ready.")

                </textarea>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; <span id="current-year"></span> Jacob Brook. All Rights Reserved.</p>
    </footer>

    <script>
        // Update footer year
        document.getElementById('current-year').textContent = new Date().getFullYear();

        const statusDiv = document.getElementById('status');
        const pythonCodeTextarea = document.getElementById('pythonCode');
        const imageUploadInput = document.getElementById('imageUpload');
        const originalImageEl = document.getElementById('originalImage');
        const outputImageEl = document.getElementById('outputImage');
        const quantizeButton = document.getElementById('quantizeButton');
        const numColorsInput = document.getElementById('numColors');
        const windowSizeInput = document.getElementById('windowSize');

        let pyodide = null;
        let originalImageBytes = null;

        async function main() {
    statusDiv.textContent = 'Pyodide Status: Loading...';
    try {
        pyodide = await loadPyodide();
        statusDiv.textContent = 'Pyodide Status: Loaded. Loading packages (numpy, Pillow, scikit-learn)...';
        // Pillow is often included with the full Pyodide distribution, 
        // but explicitly loading ensures it.
        await pyodide.loadPackage(['numpy', 'Pillow', 'scikit-learn']); 
        statusDiv.textContent = 'Pyodide Status: Packages loaded. Ready.';
        
        // Run initial Python setup code from textarea
        // This defines numpy_mode and your_quantizer_sklearn_py in Python global scope
        await pyodide.runPythonAsync(pythonCodeTextarea.value);
        statusDiv.textContent = 'Pyodide Status: Python script from textarea executed.';


    } catch (error) {
        statusDiv.textContent = `Pyodide Status: Error loading - ${error}`;
        console.error("Pyodide loading error:", error);
    }
}
main();

        imageUploadInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    originalImageEl.src = e.target.result;
                    originalImageEl.style.display = 'block';
                    // Store bytes for Python
                    const arrayBuffer = e.target.result; // This is actually a data URL here
                    // We need the actual bytes. Let's re-read as ArrayBuffer for Python.
                    const fileReaderForBytes = new FileReader();
                    fileReaderForBytes.onload = (byteEvent) => {
                        originalImageBytes = new Uint8Array(byteEvent.target.result);
                    };
                    fileReaderForBytes.readAsArrayBuffer(file);
                }
                reader.readAsDataURL(file); // For display
                outputImageEl.style.display = 'none'; // Hide previous output
                outputImageEl.src = "#";
            }
        });

        quantizeButton.addEventListener('click', async () => {
            if (!pyodide) {
                statusDiv.textContent = "Pyodide is not loaded yet.";
                return;
            }
            if (!originalImageBytes) {
                alert("Please upload an image first.");
                return;
            }

            statusDiv.textContent = "Quantizing... please wait.";
            outputImageEl.style.display = 'none';

            try {
                // Get parameters from HTML inputs
                const numColors = parseInt(numColorsInput.value);
                const windowSize = parseInt(windowSizeInput.value);

                // Make the JavaScript Uint8Array (originalImageBytes) and other parameters
                // available to the Python snippet that will call your function.
                // Pyodide will automatically convert simple JS types (numbers, strings)
                // to their Python equivalents. JS Uint8Array will be a PyProxy.
                pyodide.globals.set("js_image_bytes_for_python", originalImageBytes);
                pyodide.globals.set("js_num_colors_for_python", numColors);
                pyodide.globals.set("js_window_size_for_python", windowSize);

                // Call the Python function. The Python code string will retrieve the
                // globals we just set and pass them to the Python function.
                let resultBytesPyProxy = await pyodide.runPythonAsync(`quantizer_sklearn_py(img_arg, colors_arg, window_arg)`);

                if (resultBytesPyProxy) {
                    // Convert Python bytes (PyProxy) to JavaScript Uint8Array
                    const uint8Array = resultBytesPyProxy.toJs(); // Corrected line from previous discussion

                    const blob = new Blob([uint8Array], { type: 'image/png' });
                    const imageUrl = URL.createObjectURL(blob);
                    outputImageEl.src = imageUrl;
                    outputImageEl.style.display = 'block';
                    statusDiv.textContent = "Quantization complete!";

                    // Clean up the PyProxy to free memory
                    if (typeof resultBytesPyProxy.destroy === 'function') {
                        resultBytesPyProxy.destroy();
                    }
                } else {
                    statusDiv.textContent = "Quantization returned no data. Check console for Python errors.";
                }

            } catch (error) {
                statusDiv.textContent = `JavaScript Error during quantization: ${error}`;
                console.error("Quantization JS error:", error);
            }
        });

    </script>
</body>

</html>